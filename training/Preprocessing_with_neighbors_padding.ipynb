{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "be227cbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import *\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "67e58fcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "CONST_COLUMNS = [\n",
    "    \"Stellensubart_1\",\n",
    "    \"Stellensubart_2\",\n",
    "    \"Stellensubart_3\",\n",
    "    \"Stellensubart_4\",\n",
    "    *[f\"T{i}\" for i in range(1, 35)],\n",
    "    *[f\"TD{i:02d}\" for i in range(1, 35)],\n",
    "    \"Preis\",\n",
    "    \"Beleuchtet\",\n",
    "    \"Laenge\",\n",
    "    \"Breite\",\n",
    "    \"Eigenfläche\",\n",
    "    \"PPSVACWert\",\n",
    "    \"Qid\",\n",
    "    \"GJ\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "0656a08f",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_pickle(\"data/decade_price_data_combined_01_09.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "cf9549c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "distance_2018 = pd.read_csv(\n",
    "    \"./data/distances/distances_2018_decade_price_data_01_09.csv\"\n",
    ").set_index(\"Qid1\")\n",
    "distance_2019 = pd.read_csv(\n",
    "    \"./data/distances/distances_2019_decade_price_data_01_09.csv\"\n",
    ").set_index(\"Qid1\")\n",
    "distance_2020 = pd.read_csv(\n",
    "    \"./data/distances/distances_2020_decade_price_data_01_09.csv\"\n",
    ").set_index(\"Qid1\")\n",
    "distance_2021 = pd.read_csv(\n",
    "    \"./data/distances/distances_2021_decade_price_data_01_09.csv\"\n",
    ").set_index(\"Qid1\")\n",
    "distance_2022 = pd.read_csv(\n",
    "    \"./data/distances/distances_2022_decade_price_data_01_09.csv\"\n",
    ").set_index(\"Qid1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "de3bcdd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_data = data.sort_values(by=[\"Qid\", \"GJ\"]).set_index(\"Qid\", drop=False)\n",
    "cleaned_data = cleaned_data.loc[:, CONST_COLUMNS]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b28b7d4",
   "metadata": {},
   "source": [
    "# Normalize columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "fad262ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_of_t =['TD01', 'TD02', 'TD03', 'TD04',\n",
    "           'TD05', 'TD06', 'TD07', 'TD08', 'TD09', 'TD10', 'TD11', 'TD12', 'TD13',\n",
    "           'TD14', 'TD15', 'TD16', 'TD17', 'TD18', 'TD19', 'TD20', 'TD21', 'TD22',\n",
    "           'TD23', 'TD24', 'TD25', 'TD26', 'TD27', 'TD28', 'TD29', 'TD30', 'TD31',\n",
    "           'TD32', 'TD33', 'TD34']\n",
    "\n",
    "for i in list_of_t:\n",
    "    cleaned_data[i] = (\n",
    "        cleaned_data[i] - cleaned_data[i].mean()\n",
    "    ) / cleaned_data[i].std()\n",
    "\n",
    "cleaned_data.Preis = (\n",
    "    cleaned_data.Preis - cleaned_data.Preis.mean()\n",
    ") / cleaned_data.Preis.std()\n",
    "cleaned_data.Laenge = (\n",
    "    cleaned_data.Laenge - cleaned_data.Laenge.mean()\n",
    ") / cleaned_data.Laenge.std()\n",
    "cleaned_data.Breite = (\n",
    "    cleaned_data.Breite - cleaned_data.Breite.mean()\n",
    ") / cleaned_data.Breite.std()\n",
    "cleaned_data.PPSVACWert = (\n",
    "    cleaned_data.PPSVACWert - cleaned_data.PPSVACWert.mean()\n",
    ") / cleaned_data.PPSVACWert.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "c10dfbdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_2018 = cleaned_data[cleaned_data.GJ == 2018].drop(columns=[\"Qid\", \"GJ\"]).copy()\n",
    "data_2019 = cleaned_data[cleaned_data.GJ == 2019].drop(columns=[\"Qid\", \"GJ\"]).copy()\n",
    "data_2020 = cleaned_data[cleaned_data.GJ == 2020].drop(columns=[\"Qid\", \"GJ\"]).copy()\n",
    "data_2021 = cleaned_data[cleaned_data.GJ == 2021].drop(columns=[\"Qid\", \"GJ\"]).copy()\n",
    "data_2022 = cleaned_data[cleaned_data.GJ == 2022].drop(columns=[\"Qid\", \"GJ\"]).copy()\n",
    "data_2023 = cleaned_data[cleaned_data.GJ == 2023].drop(columns=[\"Qid\", \"GJ\"]).copy()\n",
    "\n",
    "data_2023.loc[:, \"T1\":\"T22\"] = data_2023.loc[:, \"T1\":\"T22\"].replace(-1, 0)\n",
    "all_valid_qids = cleaned_data[cleaned_data.Eigenfläche == 1].Qid.unique()\n",
    "qid_train, qid_val = train_test_split(all_valid_qids, test_size=0.05, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "e5ff5caf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def DataPreprocessor(qids):\n",
    "    \n",
    "    columns_to_drop = [\n",
    "        \"PPSVACWert\",\n",
    "        *[f\"T{i}\" for i in range(1, 35)],\n",
    "        *[f\"TD{i:02d}\" for i in range(1, 35)],\n",
    "    ]\n",
    "    \n",
    "    def pad_to_size(tensor, MAX_NEIGH):\n",
    "\n",
    "        if len(tensor.shape) != 2:\n",
    "            raise ValueError(\"Input tensor should be 2D\")\n",
    "\n",
    "        current_x, current_y = tensor.shape\n",
    "        pad_left = 0\n",
    "        pad_right = 0\n",
    "        pad_top = 0\n",
    "        pad_bottom = max(0, MAX_NEIGH - current_x)\n",
    "\n",
    "        return torch.nn.functional.pad(\n",
    "            tensor, (pad_left, pad_right, pad_top, pad_bottom), \"constant\", 0\n",
    "        )\n",
    "\n",
    "    global data_2018, data_2019, data_2020, data_2021, data_2022, data_2023\n",
    "    global distance_2018, distance_2019, distance_2020, distance_2021, distance_2022\n",
    "    X, x, y = [], [], []\n",
    "\n",
    "    all_year_data = [data_2018, data_2019, data_2020, data_2021, data_2022]\n",
    "    all_year_distances = [\n",
    "        distance_2018,\n",
    "        distance_2019,\n",
    "        distance_2020,\n",
    "        distance_2021,\n",
    "        distance_2022,\n",
    "    ]\n",
    "\n",
    "    for idx, qid in enumerate(tqdm(qids)):\n",
    "        \n",
    "        if (data_2023.index == qid).sum():\n",
    "\n",
    "            neighbours_features = []\n",
    "\n",
    "            for year_data, year_distances in zip(all_year_data, all_year_distances):\n",
    "                current_distances = year_distances[year_distances.index == qid]\n",
    "                if current_distances.shape[0] != 0:\n",
    "                    current_year_neighbours = current_distances[\n",
    "                        current_distances.Qid2 != qid\n",
    "                    ]\n",
    "                    current_year_neighbours_data = year_data.loc[current_year_neighbours.Qid2].values\n",
    "\n",
    "                    current_year_self_data = year_data.loc[qid].values\n",
    "\n",
    "                    current_year_data_point = np.concatenate(\n",
    "                        [current_year_self_data[None], current_year_neighbours_data],\n",
    "                        axis=0,\n",
    "                    )\n",
    "\n",
    "                else:\n",
    "\n",
    "                    current_year_data_point = np.zeros((1, 78))\n",
    "                    \n",
    "\n",
    "                neighbours_features.append(current_year_data_point)\n",
    "            \n",
    "            MAX_NEIGH = 0\n",
    "            for year_features in neighbours_features:\n",
    "                max_neigh = year_features.shape[0]\n",
    "                if MAX_NEIGH < max_neigh:\n",
    "                    MAX_NEIGH = max_neigh\n",
    "            \n",
    "            pad_neighbours_features = torch.zeros(0, MAX_NEIGH, 78)        \n",
    "            for year in neighbours_features:\n",
    "                pad_neighbours_features=torch.cat([pad_neighbours_features, pad_to_size(torch.tensor(year), MAX_NEIGH)[None]], dim=0)\n",
    "                \n",
    "            self_data_2023 = data_2023.loc[qid].drop(labels=columns_to_drop).values\n",
    "            \n",
    "            label = torch.tensor(data_2023.loc[qid, \"T1\":\"T22\"].mean())\n",
    "\n",
    "            X.append(pad_neighbours_features)\n",
    "            x.append(self_data_2023)\n",
    "            y.append(label)\n",
    "\n",
    "    return X, x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "c6ea0ecd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████| 63586/63586 [04:09<00:00, 255.03it/s]\n"
     ]
    }
   ],
   "source": [
    "X_train, x_train, y_train = DataPreprocessor(qid_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "54f74f91",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"./data/X_train_lstm_pad_06_09.pt\", \"wb\") as file_X:\n",
    "    pickle.dump(X_train, file_X)\n",
    "with open(\"./data/x_train_lstm_pad_06_09.pt\", \"wb\") as file_x:\n",
    "    pickle.dump(x_train, file_x)\n",
    "with open(\"./data/y_train_lstm_pad_06_09.pt\", \"wb\") as file_y:\n",
    "    pickle.dump(y_train, file_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "1c48447d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████| 3347/3347 [00:13<00:00, 246.58it/s]\n"
     ]
    }
   ],
   "source": [
    "X_val, x_val, y_val = DataPreprocessor(qid_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "5293941c",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"./data/X_val_lstm_pad_06_09.pt\", \"wb\") as file_X:\n",
    "    pickle.dump(X_val, file_X)\n",
    "    \n",
    "with open(\"./data/x_val_lstm_pad_06_09.pt\", \"wb\") as file_x:\n",
    "    pickle.dump(x_val, file_x)\n",
    "    \n",
    "with open(\"./data/y_val_lstm_pad_06_09.pt\", \"wb\") as file_y:\n",
    "    pickle.dump(y_val, file_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "09379299",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████| 4/4 [00:00<00:00, 145.92it/s]\n"
     ]
    }
   ],
   "source": [
    "X_test, x_test, y_test = DataPreprocessor([9333, 9855, 9673, 9860])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "726d411e",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"./data/X_test_lstm_pad_06_09.pt\", \"wb\") as file_X:\n",
    "    pickle.dump(X_test, file_X)\n",
    "    \n",
    "with open(\"./data/x_test_lstm_pad_06_09.pt\", \"wb\") as file_x:\n",
    "    pickle.dump(x_test, file_x)\n",
    "    \n",
    "with open(\"./data/y_test_lstm_pad_06_09.pt\", \"wb\") as file_y:\n",
    "    pickle.dump(y_test, file_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "259d1965",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
