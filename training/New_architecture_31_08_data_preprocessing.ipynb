{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "be227cbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import *\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "67e58fcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "CONST_COLUMNS = [\n",
    "    \"Stellensubart_1\",\n",
    "    \"Stellensubart_2\",\n",
    "    \"Stellensubart_3\",\n",
    "    \"Stellensubart_4\",\n",
    "    *[f\"T{i}\" for i in range(1, 35)],\n",
    "    *[f\"TD{i:02d}\" for i in range(1, 35)],\n",
    "    \"Preis\",\n",
    "    \"Beleuchtet\",\n",
    "    \"Laenge\",\n",
    "    \"Breite\",\n",
    "    \"Eigenfläche\",\n",
    "    \"PPSVACWert\",\n",
    "    \"Qid\",\n",
    "    \"GJ\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0656a08f",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_pickle(\"data/decade_price_data_combined_01_09.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cf9549c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "distance_2018 = pd.read_csv(\n",
    "    \"./data/distances/distances_2018_new_algo_200.csv\"\n",
    ").set_index(\"Qid_1\")\n",
    "distance_2019 = pd.read_csv(\n",
    "    \"./data/distances/distances_2019_new_algo_200.csv\"\n",
    ").set_index(\"Qid_1\")\n",
    "distance_2020 = pd.read_csv(\n",
    "    \"./data/distances/distances_2020_new_algo_200.csv\"\n",
    ").set_index(\"Qid_1\")\n",
    "distance_2021 = pd.read_csv(\n",
    "    \"./data/distances/distances_2021_new_algo_200.csv\"\n",
    ").set_index(\"Qid_1\")\n",
    "distance_2022 = pd.read_csv(\n",
    "    \"./data/distances/distances_2022_new_algo_200.csv\"\n",
    ").set_index(\"Qid_1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "de3bcdd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# target_year_having_qid = data[data.GJ == 2023].Qid\n",
    "# cleaned_data = data[data.Qid.isin(target_year_having_qid)]\n",
    "cleaned_data = data.sort_values(by=[\"Qid\", \"GJ\"]).set_index(\"Qid\", drop=False)\n",
    "cleaned_data = cleaned_data.loc[:, CONST_COLUMNS]\n",
    "# condition = (cleaned_data.reset_index(drop=True).groupby(\"Qid\")[\"GJ\"].apply(lambda x: x.unique().shape[0]) == cleaned_data.reset_index(drop=True).groupby(\"Qid\")[\"GJ\"].count())\n",
    "# cleaned_data = cleaned_data[cleaned_data.Qid.isin(condition[condition].index)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b28b7d4",
   "metadata": {},
   "source": [
    "# Normalize columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fad262ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_of_t =['TD01', 'TD02', 'TD03', 'TD04',\n",
    "           'TD05', 'TD06', 'TD07', 'TD08', 'TD09', 'TD10', 'TD11', 'TD12', 'TD13',\n",
    "           'TD14', 'TD15', 'TD16', 'TD17', 'TD18', 'TD19', 'TD20', 'TD21', 'TD22',\n",
    "           'TD23', 'TD24', 'TD25', 'TD26', 'TD27', 'TD28', 'TD29', 'TD30', 'TD31',\n",
    "           'TD32', 'TD33', 'TD34']\n",
    "\n",
    "for i in list_of_t:\n",
    "    cleaned_data[i] = (\n",
    "        cleaned_data[i] - cleaned_data[i].mean()\n",
    "    ) / cleaned_data[i].std()\n",
    "\n",
    "cleaned_data.Preis = (\n",
    "    cleaned_data.Preis - cleaned_data.Preis.mean()\n",
    ") / cleaned_data.Preis.std()\n",
    "cleaned_data.Laenge = (\n",
    "    cleaned_data.Laenge - cleaned_data.Laenge.mean()\n",
    ") / cleaned_data.Laenge.std()\n",
    "cleaned_data.Breite = (\n",
    "    cleaned_data.Breite - cleaned_data.Breite.mean()\n",
    ") / cleaned_data.Breite.std()\n",
    "cleaned_data.PPSVACWert = (\n",
    "    cleaned_data.PPSVACWert - cleaned_data.PPSVACWert.mean()\n",
    ") / cleaned_data.PPSVACWert.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c10dfbdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_2018 = cleaned_data[cleaned_data.GJ == 2018].drop(columns=[\"Qid\", \"GJ\"]).copy()\n",
    "data_2019 = cleaned_data[cleaned_data.GJ == 2019].drop(columns=[\"Qid\", \"GJ\"]).copy()\n",
    "data_2020 = cleaned_data[cleaned_data.GJ == 2020].drop(columns=[\"Qid\", \"GJ\"]).copy()\n",
    "data_2021 = cleaned_data[cleaned_data.GJ == 2021].drop(columns=[\"Qid\", \"GJ\"]).copy()\n",
    "data_2022 = cleaned_data[cleaned_data.GJ == 2022].drop(columns=[\"Qid\", \"GJ\"]).copy()\n",
    "data_2023 = cleaned_data[cleaned_data.GJ == 2023].drop(columns=[\"Qid\", \"GJ\"]).copy()\n",
    "\n",
    "data_2023.loc[:, \"T1\":\"T22\"] = data_2023.loc[:, \"T1\":\"T22\"].replace(-1, 0)\n",
    "all_valid_qids = cleaned_data[cleaned_data.Eigenfläche == 1].Qid.unique()\n",
    "qid_train, qid_val = train_test_split(all_valid_qids, test_size=0.05, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e5ff5caf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def DataPreprocessor(qids):\n",
    "    \n",
    "    MAX_NEIGH = 10\n",
    "    columns_to_drop = [\n",
    "        \"PPSVACWert\",\n",
    "        *[f\"T{i}\" for i in range(1, 35)],\n",
    "        *[f\"TD{i:02d}\" for i in range(1, 35)],\n",
    "    ]\n",
    "\n",
    "    global data_2018, data_2019, data_2020, data_2021, data_2022, data_2023\n",
    "    global distance_2018, distance_2019, distance_2020, distance_2021, distance_2022\n",
    "    X, x, y = [], [], []\n",
    "\n",
    "    all_year_data = [data_2018, data_2019, data_2020, data_2021, data_2022]\n",
    "    all_year_distances = [\n",
    "        distance_2018,\n",
    "        distance_2019,\n",
    "        distance_2020,\n",
    "        distance_2021,\n",
    "        distance_2022,\n",
    "    ]\n",
    "\n",
    "    for idx, qid in enumerate(tqdm(qids)):\n",
    "        \n",
    "        if (data_2023.index == qid).sum():\n",
    "\n",
    "            neighbours_features = []\n",
    "\n",
    "            for year_data, year_distances in zip(all_year_data, all_year_distances):\n",
    "                current_distances = year_distances[year_distances.index == qid]\n",
    "                if (current_distances.shape[0] != 0) and ((year_data.index == qid).sum() != 0):\n",
    "                    current_year_neighbours = current_distances[\n",
    "                        current_distances.Qid_2 != qid\n",
    "                    ]\n",
    "                    \n",
    "                    current_year_neighbours_data = year_data[year_data.index.isin(current_year_neighbours.Qid_2)].values\n",
    "#                     torch.from_numpy(\n",
    "                        \n",
    "#                     )\n",
    "                    \n",
    "#                     current_year_neighbours_data = year_data.loc[current_year_neighbours.Qid2].values\n",
    "    #                 current_year_neighbours_data_padded = pad(\n",
    "    #                     current_year_neighbours_data,\n",
    "    #                     (0, 0, 0, MAX_NEIGH - current_year_neighbours_data.shape[0]),\n",
    "    #                     \"constant\",\n",
    "    #                     0,\n",
    "    #                 )\n",
    "\n",
    "                    current_year_self_data = year_data.loc[qid].values\n",
    "\n",
    "    #                 if (current_year_self_data.ndim == 2) and (\n",
    "    #                     current_year_self_data.shape[0] > 1\n",
    "    #                 ):\n",
    "    #                     current_year_self_data = current_year_self_data[0]\n",
    "\n",
    "                    current_year_data_point = np.concatenate(\n",
    "                        [current_year_self_data[None], current_year_neighbours_data],\n",
    "                        axis=0,\n",
    "                    )\n",
    "\n",
    "                else:\n",
    "                    #TODO: fill dummpy -1 for that Qid, and find that year neighbours.\n",
    "\n",
    "                    current_year_data_point = np.zeros((1, 78))\n",
    "\n",
    "                neighbours_features.append(current_year_data_point)\n",
    "\n",
    "\n",
    "            self_data_2023 = data_2023.loc[qid].drop(labels=columns_to_drop).values\n",
    "\n",
    "            neighbours_features = np.array(neighbours_features, dtype=object)\n",
    "            label = torch.tensor(data_2023.loc[qid, \"T1\":\"T22\"].mean())\n",
    "\n",
    "            X.append(neighbours_features)\n",
    "            x.append(self_data_2023)\n",
    "            y.append(label)\n",
    "\n",
    "    return X, x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c6ea0ecd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████| 63586/63586 [11:34<00:00, 91.49it/s]\n"
     ]
    }
   ],
   "source": [
    "X_train, x_train, y_train = DataPreprocessor(qid_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "54f74f91",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"./data/X_train_lstm_new_arch_new_algo_200.pt\", \"wb\") as file_X:\n",
    "    pickle.dump(X_train, file_X)\n",
    "with open(\"./data/x_train_lstm_new_arch_new_algo_200.pt\", \"wb\") as file_x:\n",
    "    pickle.dump(x_train, file_x)\n",
    "with open(\"./data/y_train_lstm_new_arch_new_algo_200.pt\", \"wb\") as file_y:\n",
    "    pickle.dump(y_train, file_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1c48447d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████| 3347/3347 [00:36<00:00, 92.45it/s]\n"
     ]
    }
   ],
   "source": [
    "X_val, x_val, y_val = DataPreprocessor(qid_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5293941c",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"./data/X_val_lstm_new_arch_new_algo_200.pt\", \"wb\") as file_X:\n",
    "    pickle.dump(X_val, file_X)\n",
    "    \n",
    "with open(\"./data/x_val_lstm_new_arch_new_algo_200.pt\", \"wb\") as file_x:\n",
    "    pickle.dump(x_val, file_x)\n",
    "    \n",
    "with open(\"./data/y_val_lstm_new_arch_new_algo_200.pt\", \"wb\") as file_y:\n",
    "    pickle.dump(y_val, file_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "09379299",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████| 4/4 [00:00<00:00, 52.42it/s]\n"
     ]
    }
   ],
   "source": [
    "X_test, x_test, y_test = DataPreprocessor([9860, 9673, 9855, 9333])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "726d411e",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"./data/X_test_lstm_new_arch_new_algo.pt\", \"wb\") as file_X:\n",
    "    pickle.dump(X_test, file_X)\n",
    "    \n",
    "with open(\"./data/x_test_lstm_new_arch_new_algo.pt\", \"wb\") as file_x:\n",
    "    pickle.dump(x_test, file_x)\n",
    "    \n",
    "with open(\"./data/y_test_lstm_new_arch_new_algo.pt\", \"wb\") as file_y:\n",
    "    pickle.dump(y_test, file_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58a3858d",
   "metadata": {},
   "source": [
    "### Combine data with td and old data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "19c836e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "old_df = pd.read_pickle(\"./data/df_gesamt_15_08_prepocessed_einworner_added.pkl\")\n",
    "old_df.drop(\"Einwohner\", inplace=True, axis=1)\n",
    "new_df = pd.read_pickle(\"./data/decade_price_data_combined.pkl\")\n",
    "condition = (new_df.reset_index(drop=True).groupby(\"Qid\")[\"GJ\"].apply(lambda x: x.unique().shape[0]) == new_df.reset_index(drop=True).groupby(\"Qid\")[\"GJ\"].count())\n",
    "new_df = new_df[new_df.Qid.isin(condition[condition].index)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a40187c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['GJ', 'Qid', 'TD01', 'TD02', 'TD03', 'TD04', 'TD05', 'TD06', 'TD07',\n",
       "       'TD08', 'TD09', 'TD10', 'TD11', 'TD12', 'TD13', 'TD14', 'TD15', 'TD16',\n",
       "       'TD17', 'TD18', 'TD19', 'TD20', 'TD21', 'TD22', 'TD23', 'TD24', 'TD25',\n",
       "       'TD26', 'TD27', 'TD28', 'TD29', 'TD30', 'TD31', 'TD32', 'TD33', 'TD34',\n",
       "       'Ort', 'Preis', 'PLZ', 'Beleuchtet', 'Laenge', 'Breite', 'PPSVACWert',\n",
       "       'T1', 'T2', 'T3', 'T4', 'T5', 'T6', 'T7', 'T8', 'T9', 'T10', 'T11',\n",
       "       'T12', 'T13', 'T14', 'T15', 'T16', 'T17', 'T18', 'T19', 'T20', 'T21',\n",
       "       'T22', 'T23', 'T24', 'T25', 'T26', 'T27', 'T28', 'T29', 'T30', 'T31',\n",
       "       'T32', 'T33', 'T34', 'Eigenfläche', 'Stellensubart_1',\n",
       "       'Stellensubart_2', 'Stellensubart_3', 'Stellensubart_4'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "df5fba83",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_of_t = ['TD01', 'TD02', 'TD03', 'TD04', 'TD05', 'TD06', 'TD07',\n",
    "     'TD08', 'TD09', 'TD10', 'TD11', 'TD12', 'TD13', 'TD14', 'TD15', 'TD16',\n",
    "     'TD17', 'TD18', 'TD19', 'TD20', 'TD21', 'TD22', 'TD23', 'TD24', 'TD25',\n",
    "     'TD26', 'TD27', 'TD28', 'TD29', 'TD30', 'TD31', 'TD32', 'TD33', 'TD34', 'Preis']\n",
    "\n",
    "for i in list_of_t:\n",
    "    old_df[i] = old_df.Preis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9b303cd6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((813064, 82), (319594, 82))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "old_df.shape, new_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5c8b5e02",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined = pd.concat([new_df, old_df[~(old_df.Qid.isin(new_df.Qid.unique()))]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "259d1965",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(806415, 82)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8a60dafa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>GJ</th>\n",
       "      <th>Qid</th>\n",
       "      <th>TD01</th>\n",
       "      <th>TD02</th>\n",
       "      <th>TD03</th>\n",
       "      <th>TD04</th>\n",
       "      <th>TD05</th>\n",
       "      <th>TD06</th>\n",
       "      <th>TD07</th>\n",
       "      <th>TD08</th>\n",
       "      <th>...</th>\n",
       "      <th>T30</th>\n",
       "      <th>T31</th>\n",
       "      <th>T32</th>\n",
       "      <th>T33</th>\n",
       "      <th>T34</th>\n",
       "      <th>Eigenfläche</th>\n",
       "      <th>Stellensubart_1</th>\n",
       "      <th>Stellensubart_2</th>\n",
       "      <th>Stellensubart_3</th>\n",
       "      <th>Stellensubart_4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2018.0</td>\n",
       "      <td>100019.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.427</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52544</th>\n",
       "      <td>2019.0</td>\n",
       "      <td>100019.0</td>\n",
       "      <td>0.650000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106327</th>\n",
       "      <td>2020.0</td>\n",
       "      <td>100019.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>5.967000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.967</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>160287</th>\n",
       "      <td>2022.0</td>\n",
       "      <td>100019.0</td>\n",
       "      <td>1.176364</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.294</td>\n",
       "      <td>6.183636</td>\n",
       "      <td>1.294000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>213041</th>\n",
       "      <td>2021.0</td>\n",
       "      <td>100019.0</td>\n",
       "      <td>6.427273</td>\n",
       "      <td>0.000</td>\n",
       "      <td>2.156</td>\n",
       "      <td>1.960000</td>\n",
       "      <td>0.715000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>268236</th>\n",
       "      <td>2023.0</td>\n",
       "      <td>100019.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.411</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.282727</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.282727</td>\n",
       "      <td>0.000</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6 rows × 82 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            GJ       Qid      TD01   TD02   TD03      TD04      TD05   TD06  \\\n",
       "0       2018.0  100019.0  0.000000  0.000  0.000  0.000000  0.000000  0.000   \n",
       "52544   2019.0  100019.0  0.650000  0.000  0.000  0.000000  0.000000  0.000   \n",
       "106327  2020.0  100019.0  0.000000  0.000  0.000  5.967000  0.000000  5.967   \n",
       "160287  2022.0  100019.0  1.176364  0.000  1.294  6.183636  1.294000  0.000   \n",
       "213041  2021.0  100019.0  6.427273  0.000  2.156  1.960000  0.715000  0.000   \n",
       "268236  2023.0  100019.0  0.000000  1.411  0.000  0.000000  1.282727  0.000   \n",
       "\n",
       "            TD07   TD08  ...  T30  T31  T32  T33  T34  Eigenfläche  \\\n",
       "0       0.000000  6.427  ...  1.0  0.0  0.0  0.0  0.0          1.0   \n",
       "52544   0.000000  0.000  ...  0.0  0.0  0.0  0.0  0.0          1.0   \n",
       "106327  0.000000  0.000  ...  0.0  0.0  0.0  0.0  0.0          1.0   \n",
       "160287  0.000000  0.000  ...  0.0  0.0  0.0  0.0  0.0          1.0   \n",
       "213041  0.000000  0.000  ...  0.0  0.0  0.0  0.0  1.0          1.0   \n",
       "268236  1.282727  0.000  ... -1.0 -1.0 -1.0 -1.0 -1.0          1.0   \n",
       "\n",
       "        Stellensubart_1  Stellensubart_2  Stellensubart_3  Stellensubart_4  \n",
       "0                   0.0              0.0              0.0              0.0  \n",
       "52544               0.0              0.0              0.0              0.0  \n",
       "106327              0.0              0.0              0.0              0.0  \n",
       "160287              0.0              0.0              0.0              0.0  \n",
       "213041              0.0              0.0              0.0              0.0  \n",
       "268236              0.0              0.0              0.0              0.0  \n",
       "\n",
       "[6 rows x 82 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined[combined.Qid == 100019.0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "50640f6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined.to_pickle(\"./data/decade_price_data_combined_01_09.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "891df2a9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
