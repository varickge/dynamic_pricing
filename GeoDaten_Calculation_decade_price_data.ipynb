{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "957b4e52",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import math\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "# from haversine import haversine, Unit #It can also be used to calculate the haversine distance, but a loop is needed to iterate over lat and lon."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5ddfaa86",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_pickle('./data/decade_price_data_combined.pkl')\n",
    "data['GJ'] = data['GJ'].astype(float, errors='raise')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa6dbd03",
   "metadata": {},
   "source": [
    "# Truncated missing years"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "18e2d4c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_year_having_qid = data[data.GJ == 2023].Qid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "874019f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data[data.Qid.isin(target_year_having_qid)].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bc1c9098",
   "metadata": {},
   "outputs": [],
   "source": [
    "# splitting data to years\n",
    "data_2018 = data[data[\"GJ\"] == 2018]\n",
    "data_2019 = data[data[\"GJ\"] == 2019]\n",
    "data_2020 = data[data[\"GJ\"] == 2020]\n",
    "data_2021 = data[data[\"GJ\"] == 2021]\n",
    "data_2022 = data[data[\"GJ\"] == 2022]\n",
    "data_2023 = data[data[\"GJ\"] == 2023]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "999ce764",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # haversine distance calculator function \n",
    "\n",
    "def haversine_distance(lat1, lon1, lat2, lon2):\n",
    "    \"\"\"\n",
    "    Calculate the Haversine distance between two points on the Earth.\n",
    "\n",
    "    Parameters:\n",
    "    - lat1 (float): Latitude of the first point in degrees.\n",
    "    - lon1 (float): Longitude of the first point in degrees.\n",
    "    - lat2 (float): Latitude of the second point in degrees.\n",
    "    - lon2 (float): Longitude of the second point in degrees.\n",
    "\n",
    "    Returns:\n",
    "    - float: Distance between the two points in meters.\n",
    "\n",
    "    Note:\n",
    "    This function assumes the Earth is a perfect sphere with a radius of 6,371,000 meters.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Convert latitude and longitude from degrees to radians\n",
    "    lat1, lon1, lat2, lon2 = np.radians([lat1, lon1, lat2, lon2])\n",
    "\n",
    "    # Haversine formula \n",
    "    dlat = lat2 - lat1\n",
    "    dlon = lon2 - lon1\n",
    "    a = np.sin(dlat/2.0)**2 + np.cos(lat1) * np.cos(lat2) * np.sin(dlon/2.0)**2\n",
    "    c = 2 * np.arctan2(np.sqrt(a), np.sqrt(1-a))\n",
    "\n",
    "    # Radius of Earth in kilometers\n",
    "    r = 6371.0\n",
    "    return r * c\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "da8c1aca",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_distances(data, max_dist=0.2):\n",
    "    # changing type of data for agg\n",
    "    data.PLZ = data.PLZ.astype('float64')\n",
    "\n",
    "    # taking unique \"Qid\"s and max of other (PLZ, AU, etc) columns\n",
    "#     data = data.groupby(\"Qid\").agg({'PLZ': 'max', 'Au': 'max', 'Laenge': 'max', 'Breite': 'max'}).reset_index()\n",
    "    data = data.groupby(\"Qid\").agg({'PLZ': 'max', 'Laenge': 'max', 'Breite': 'max'}).reset_index()\n",
    "    \n",
    "\n",
    "    # cutting `plz`, e.g. plz[0] is 34678, now plz[0] is 346 (Clustering regions with zip code). \n",
    "    data['join'] = data['PLZ'].astype(str).apply(lambda x: x[:3])\n",
    "\n",
    "    # copying data for distance calculation\n",
    "    data_copy1 = data.copy()\n",
    "    data_copy2 = data.copy()\n",
    "\n",
    "    # merging the same df for commonality\n",
    "    ergebnis = pd.merge(data_copy1, data_copy2, on='join', suffixes=['1', '2'])\n",
    "\n",
    "    # defining longitudes and latitudes\n",
    "    lat1 = np.array(ergebnis['Laenge1'].values)\n",
    "    lat2 = np.array(ergebnis['Laenge2'].values)\n",
    "    lon1 = np.array(ergebnis['Breite1'].values)\n",
    "    lon2 = np.array(ergebnis['Breite2'].values)\n",
    "    \n",
    "    # calculating distances and applying to the df\n",
    "    ergebnis['distance'] = haversine_distance(lat1, lon1, lat2, lon2)\n",
    "\n",
    "    # clustering data with max_dist param\n",
    "    ergebnis = ergebnis[(ergebnis['distance'] >= 0) & (ergebnis['distance'] <= max_dist)]\n",
    "\n",
    "    # dropping unnecessary columns\n",
    "#     ergebnis.drop(columns=[\"PLZ1\", \"Au1\", \"Laenge1\", \"Breite1\", \"join\", \"PLZ2\", \"Au2\", \"Laenge2\", \"Breite2\"], axis=1, inplace=True) \n",
    "    ergebnis.drop(columns=[\"PLZ1\", \"Laenge1\", \"Breite1\", \"join\", \"PLZ2\", \"Laenge2\", \"Breite2\"], axis=1, inplace=True) \n",
    "\n",
    "    return ergebnis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2d72cd10",
   "metadata": {},
   "outputs": [],
   "source": [
    "distances_2018 = calc_distances(data_2018.copy())\n",
    "distances_2019 = calc_distances(data_2019.copy())\n",
    "distances_2020 = calc_distances(data_2020.copy())\n",
    "distances_2021 = calc_distances(data_2021.copy())\n",
    "distances_2022 = calc_distances(data_2022.copy())\n",
    "distances_2023 = calc_distances(data_2023.copy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3120b46c-146b-4118-b2b9-cdc69a969d84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018:  (227913, 3)\n",
      "2019:  (241053, 3)\n",
      "2020:  (249025, 3)\n",
      "2021:  (257902, 3)\n",
      "2022:  (263806, 3)\n",
      "2023:  (270407, 3)\n"
     ]
    }
   ],
   "source": [
    "print(\"2018: \", distances_2018.shape)\n",
    "print(\"2019: \", distances_2019.shape)\n",
    "print(\"2020: \", distances_2020.shape)\n",
    "print(\"2021: \", distances_2021.shape)\n",
    "print(\"2022: \", distances_2022.shape)\n",
    "print(\"2023: \", distances_2023.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e5c2b8f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "distances_2018.to_csv(\"data/distances/distances_2018_decade_price_data.csv\", index=False)\n",
    "distances_2019.to_csv(\"data/distances/distances_2019_decade_price_data.csv\", index=False)\n",
    "distances_2020.to_csv(\"data/distances/distances_2020_decade_price_data.csv\", index=False)\n",
    "distances_2021.to_csv(\"data/distances/distances_2021_decade_price_data.csv\", index=False)\n",
    "distances_2022.to_csv(\"data/distances/distances_2022_decade_price_data.csv\", index=False)\n",
    "distances_2023.to_csv(\"data/distances/distances_2023_decade_price_data.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
