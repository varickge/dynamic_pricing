{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "798b47e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import math\n",
    "from pathlib import Path\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn.functional import pad\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    DEVICE = torch.device(\"cuda:1\")\n",
    "else:\n",
    "    DEVICE = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "868d6a59",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_pickle(\"./final_data/data.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "11170fd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTMModel_1(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_layers, output_size):\n",
    "        super(LSTMModel_1, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        self.lstm = nn.LSTM(\n",
    "            input_size,\n",
    "            hidden_size,\n",
    "            num_layers,\n",
    "            batch_first=True,\n",
    "            bias=True,\n",
    "            dropout=0.0,\n",
    "        )\n",
    "\n",
    "        self.fc_1 = nn.Sequential(\n",
    "            nn.Linear(11, 1),\n",
    "        )\n",
    "\n",
    "        self.fc_2 = nn.Sequential(\n",
    "            nn.Linear(hidden_size // 1, hidden_size // 2),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.BatchNorm1d(hidden_size // 2),\n",
    "            nn.Dropout1d(0.0),\n",
    "            nn.Linear(hidden_size // 2, hidden_size // 4),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Dropout1d(0.0),\n",
    "            nn.Linear(hidden_size // 4, hidden_size // 8),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.Dropout1d(0.0),\n",
    "            nn.Linear(hidden_size // 8, output_size),\n",
    "        )\n",
    "\n",
    "        self.fc_b = nn.Linear(input_size - 69, input_size)\n",
    "\n",
    "    def forward(self, x, x_2023):\n",
    "        out = self.fc_1(x)\n",
    "        out = out[..., 0]\n",
    "\n",
    "        x_2023 = self.fc_b(x_2023)[:, None, ...]\n",
    "        out = torch.cat([out, x_2023], dim=1)\n",
    "\n",
    "        out, _ = self.lstm(out)\n",
    "        out = out[:, -1, ...]\n",
    "        out = self.fc_2(out)\n",
    "\n",
    "        return out\n",
    "\n",
    "\n",
    "class PriceOptimizer:\n",
    "    def __init__(\n",
    "        self,\n",
    "        data_root_dir,\n",
    "        out_root_dir,\n",
    "        price_min,\n",
    "        price_max,\n",
    "        price_num,\n",
    "    ):\n",
    "        data_root_dir = Path(data_root_dir)\n",
    "\n",
    "        if not data_root_dir.is_dir():\n",
    "            raise ValueError(\n",
    "                f\"The directory {data_root_dir.as_posix()} does not exist.\"\n",
    "            )\n",
    "\n",
    "        out_root_dir = Path(out_root_dir)\n",
    "\n",
    "        if not out_root_dir.is_dir():\n",
    "            raise ValueError(f\"The directory {out_root_dir.as_posix()} does not exist.\")\n",
    "\n",
    "        if not isinstance(price_min, (int, float)):\n",
    "            raise TypeError(\n",
    "                f\"Expected price_min to be type of int or float, but got {type(price_min)}.\"\n",
    "            )\n",
    "\n",
    "        if not isinstance(price_max, (int, float)):\n",
    "            raise TypeError(\n",
    "                f\"Expected price_max to be type of int or float, but got {type(price_max)}.\"\n",
    "            )\n",
    "\n",
    "        if not isinstance(price_num, int):\n",
    "            raise TypeError(\n",
    "                f\"Expected price_num to be type of int, but got {type(price_num)}.\"\n",
    "            )\n",
    "\n",
    "        if price_max <= price_min:\n",
    "            raise ValueError(f\"Inconsistent price range.\")\n",
    "\n",
    "        if not (10 <= price_num <= 2000):\n",
    "            raise ValueError(f\"Inconsistent price_num.\")\n",
    "\n",
    "        self.out_dir = out_root_dir\n",
    "        self.data_root_dir = data_root_dir\n",
    "        self.price_min = price_min\n",
    "        self.price_max = price_max\n",
    "        self.price_num = price_num\n",
    "\n",
    "        # read the data\n",
    "\n",
    "        data_path = data_root_dir / \"data.pkl\"\n",
    "\n",
    "        if not data_path.is_file():\n",
    "            raise ValueError(f\"The file {data_path.as_posix()} does not exist.\")\n",
    "\n",
    "        self.data = pd.read_pickle(data_path)\n",
    "\n",
    "        # calculate price mean and std\n",
    "        self.price_mean = self.data.Preis.mean()\n",
    "        self.price_std = self.data.Preis.std()\n",
    "\n",
    "        # load model\n",
    "        self.nn = LSTMModel_1(78, 512, 5, 1).to(device=DEVICE).eval()\n",
    "        self.nn.load_state_dict(torch.load(\"./final_data/dense_lstm_model.pt\"))\n",
    "\n",
    "        # preprocess the data\n",
    "        self.__preprocess_data()\n",
    "\n",
    "        # load distance data\n",
    "        self.__load_distance_data()\n",
    "\n",
    "    def __load_distance_data(self):\n",
    "        self.distance_2018 = pd.read_csv(\n",
    "            self.data_root_dir / \"distances_2018.csv\"\n",
    "        ).set_index(\"Qid_1\")\n",
    "        self.distance_2019 = pd.read_csv(\n",
    "            self.data_root_dir / \"distances_2019.csv\"\n",
    "        ).set_index(\"Qid_1\")\n",
    "        self.distance_2020 = pd.read_csv(\n",
    "            self.data_root_dir / \"distances_2020.csv\"\n",
    "        ).set_index(\"Qid_1\")\n",
    "        self.distance_2021 = pd.read_csv(\n",
    "            self.data_root_dir / \"distances_2021.csv\"\n",
    "        ).set_index(\"Qid_1\")\n",
    "        self.distance_2022 = pd.read_csv(\n",
    "            self.data_root_dir / \"distances_2022.csv\"\n",
    "        ).set_index(\"Qid_1\")\n",
    "        self.distance_2023 = pd.read_csv(\n",
    "            self.data_root_dir / \"distances_2023.csv\"\n",
    "        ).set_index(\"Qid_1\")\n",
    "        \n",
    "    def __normalize_columns(self):\n",
    "        global std_, mean_ \n",
    "        std_, mean_=self.cleaned_data.PPSVACWert.std(), self.cleaned_data.PPSVACWert.mean()\n",
    "        self.cleaned_data.Preis = (\n",
    "            self.cleaned_data.Preis - self.cleaned_data.Preis.mean()\n",
    "        ) / self.cleaned_data.Preis.std()\n",
    "        self.cleaned_data.Laenge = (\n",
    "            self.cleaned_data.Laenge - self.cleaned_data.Laenge.mean()\n",
    "        ) / self.cleaned_data.Laenge.std()\n",
    "        self.cleaned_data.Breite = (\n",
    "            self.cleaned_data.Breite - self.cleaned_data.Breite.mean()\n",
    "        ) / self.cleaned_data.Breite.std()\n",
    "        self.cleaned_data.PPSVACWert = (\n",
    "            self.cleaned_data.PPSVACWert - self.cleaned_data.PPSVACWert.mean()\n",
    "        ) / self.cleaned_data.PPSVACWert.std()\n",
    "\n",
    "         \n",
    "        list_of_t = [f\"TD{i:02d}\" for i in range(1, 35)]\n",
    "\n",
    "        for i in list_of_t:\n",
    "            self.cleaned_data[i] = (\n",
    "                self.cleaned_data[i] - self.cleaned_data[i].mean()\n",
    "            ) / self.cleaned_data[i].std()\n",
    "    \n",
    "\n",
    "    def __separate_data(self):\n",
    "        self.data_2018 = (\n",
    "            self.cleaned_data[self.cleaned_data.GJ == 2018]\n",
    "            .drop(columns=[\"Qid\", \"GJ\"])\n",
    "            .copy()\n",
    "        )\n",
    "        self.data_2019 = (\n",
    "            self.cleaned_data[self.cleaned_data.GJ == 2019]\n",
    "            .drop(columns=[\"Qid\", \"GJ\"])\n",
    "            .copy()\n",
    "        )\n",
    "        self.data_2020 = (\n",
    "            self.cleaned_data[self.cleaned_data.GJ == 2020]\n",
    "            .drop(columns=[\"Qid\", \"GJ\"])\n",
    "            .copy()\n",
    "        )\n",
    "        self.data_2021 = (\n",
    "            self.cleaned_data[self.cleaned_data.GJ == 2021]\n",
    "            .drop(columns=[\"Qid\", \"GJ\"])\n",
    "            .copy()\n",
    "        )\n",
    "        self.data_2022 = (\n",
    "            self.cleaned_data[self.cleaned_data.GJ == 2022]\n",
    "            .drop(columns=[\"Qid\", \"GJ\"])\n",
    "            .copy()\n",
    "        )\n",
    "        self.data_2023 = (\n",
    "            self.cleaned_data[self.cleaned_data.GJ == 2023]\n",
    "            .drop(columns=[\"Qid\", \"GJ\"])\n",
    "            .copy()\n",
    "        )\n",
    "    \n",
    "    def __preprocess_data(self):\n",
    "        CONST_COLUMNS = [\n",
    "            \"Stellensubart_1\",\n",
    "            \"Stellensubart_2\",\n",
    "            \"Stellensubart_3\",\n",
    "            \"Stellensubart_4\",\n",
    "            *[f\"T{i}\" for i in range(1, 35)],\n",
    "            *[f\"TD{i:02d}\" for i in range(1, 35)],\n",
    "            \"Preis\",\n",
    "            \"Beleuchtet\",\n",
    "            \"Laenge\",\n",
    "            \"Breite\",\n",
    "            \"EigenflÃ¤che\",\n",
    "            \"PPSVACWert\",\n",
    "            \"Qid\",\n",
    "            \"GJ\",\n",
    "        ]\n",
    "\n",
    "        # set Qid column as index and take the required columns\n",
    "        cleaned_data = self.data.set_index(\"Qid\", drop=False)\n",
    "        cleaned_data.Qid = cleaned_data.Qid.astype(int)\n",
    "        self.cleaned_data = cleaned_data.loc[:, CONST_COLUMNS]\n",
    "        # normalize the data\n",
    "        self.__normalize_columns()\n",
    "        # separate the data into years\n",
    "        self.__separate_data()       \n",
    "\n",
    "    def __get_qid_data(self, qid):\n",
    "        if (self.cleaned_data.index == qid).sum() == 0:\n",
    "            raise ValueError(f\"Unknown qid {qid}\")\n",
    "\n",
    "        if (self.data_2023.index == qid).sum() == 0:\n",
    "            raise ValueError(f\"There is no information for qid {qid} for 2023 year.\")\n",
    "        MAX_NEIGH = 10\n",
    "\n",
    "        # columns which will be dropped for target year (2023)\n",
    "        columns_to_drop = [\n",
    "            \"PPSVACWert\",\n",
    "            *[f\"T{i}\" for i in range(1, 35)],\n",
    "            *[f\"TD{i:02d}\" for i in range(1, 35)],\n",
    "        ]\n",
    "\n",
    "        neighbours_features = []\n",
    "\n",
    "        all_year_data = [\n",
    "            self.data_2018,\n",
    "            self.data_2019,\n",
    "            self.data_2020,\n",
    "            self.data_2021,\n",
    "            self.data_2022,\n",
    "        ]\n",
    "\n",
    "        all_year_distances = [\n",
    "            self.distance_2018,\n",
    "            self.distance_2019,\n",
    "            self.distance_2020,\n",
    "            self.distance_2021,\n",
    "            self.distance_2022,\n",
    "        ]\n",
    "\n",
    "        for year_data, year_distances in zip(all_year_data, all_year_distances):\n",
    "            current_distances = year_distances[year_distances.index == qid]\n",
    "\n",
    "            if (current_distances.shape[0] != 0) and (\n",
    "                (year_data.index == qid).sum() != 0\n",
    "            ):\n",
    "                current_year_neighbours = current_distances[\n",
    "                    current_distances.Qid_2 != qid\n",
    "                ]\n",
    "\n",
    "                current_year_neighbours_data = torch.from_numpy(\n",
    "                    year_data[\n",
    "                        year_data.index.isin(current_year_neighbours.Qid_2)\n",
    "                    ].values\n",
    "                )\n",
    "                current_year_neighbours_data_padded = pad(\n",
    "                    current_year_neighbours_data,\n",
    "                    (0, 0, 0, MAX_NEIGH - current_year_neighbours_data.shape[0]),\n",
    "                    \"constant\",\n",
    "                    0,\n",
    "                )\n",
    "\n",
    "                current_year_self_data = torch.from_numpy(year_data.loc[qid].values)\n",
    "\n",
    "                if (current_year_self_data.ndim == 2) and (\n",
    "                    current_year_self_data.shape[0] > 1\n",
    "                ):\n",
    "                    current_year_self_data = current_year_self_data[0]\n",
    "\n",
    "                current_year_data_point = torch.cat(\n",
    "                    [current_year_self_data[None], current_year_neighbours_data_padded],\n",
    "                    dim=0,\n",
    "                )\n",
    "\n",
    "            else:\n",
    "                current_year_data_point = torch.zeros(11, 78)\n",
    "\n",
    "            neighbours_features.append(current_year_data_point)\n",
    "            \n",
    "        neighbors_2023 = self.distance_2023[self.distance_2023.index == qid].Qid_2\n",
    "        areas = self.data_2023[self.data_2023.index.isin(neighbors_2023)]['EigenflÃ¤che'].values\n",
    "        own_areas = areas[areas==1]\n",
    "        self_data_2023 = torch.from_numpy(\n",
    "            self.data_2023.loc[qid].drop(labels=columns_to_drop).values\n",
    "        )\n",
    "\n",
    "        neighbours_features = torch.stack(neighbours_features, dim=0)\n",
    "        label = torch.tensor(self.data_2023.loc[qid, \"T1\":\"T22\"].replace(-1, np.nan).mean())\n",
    "        try:\n",
    "            booking_2022 = torch.tensor(self.data_2022.loc[qid, \"T1\":\"T22\"].replace(-1, np.nan).mean()).item()\n",
    "        except:\n",
    "            booking_2022 = float(\"nan\")\n",
    "        PPS = torch.tensor(self.data_2023.loc[qid, \"PPSVACWert\"])\n",
    "        PPS = PPS*std_ + mean_\n",
    "        return neighbours_features, self_data_2023, booking_2022, PPS.item(), areas.shape, own_areas.shape, label\n",
    "\n",
    "    def __grid_search(self, qid_data):\n",
    "        data_X, data_x = qid_data\n",
    "\n",
    "        data_X = data_X[None].permute(0, 1, 3, 2).to(dtype=torch.float32, device=DEVICE)\n",
    "        data_x = data_x[None].to(dtype=torch.float32, device=DEVICE)\n",
    "\n",
    "        history = np.zeros((3, self.price_num))\n",
    "\n",
    "        # denormalize the price\n",
    "        original_price = data_x[:, -5].item() * self.price_std + self.price_mean\n",
    "\n",
    "        data_X = data_X.repeat(self.price_num, 1, 1, 1)\n",
    "        data_x = data_x.repeat(self.price_num, 1)\n",
    "\n",
    "        price_grid = torch.linspace(self.price_min, self.price_max, self.price_num)\n",
    "        data_x[:, -5] = (price_grid - self.price_mean) / self.price_std\n",
    "\n",
    "        mean_b = self.nn(data_X, data_x).detach().cpu().numpy()[..., 0]\n",
    "        reward = price_grid * mean_b\n",
    "        history[0] = price_grid\n",
    "        history[1] = mean_b\n",
    "        history[2] = reward\n",
    "\n",
    "        return original_price, history, mean_b\n",
    "\n",
    "    def __find_optimum(self, history, original_price, mean_b):\n",
    "        def find_nearest(array, value, idxis=False):\n",
    "            array = np.asarray(array)\n",
    "            idx = (np.abs(array - value)).argmin()\n",
    "            if idxis:\n",
    "                return idx\n",
    "            return array[idx], idx\n",
    "        \n",
    "        def find_volume(array, peak, value, idxis=False):\n",
    "            # find nearest indices and values around 'peak'to 95% of reward\n",
    "            array = np.asarray(array)\n",
    "            idx=[]\n",
    "            idx.append((np.abs(array[:peak] - value)).argsort()[:1])\n",
    "            idx.append((np.abs(array[peak:] - value)).argsort()[:1]+peak)\n",
    "            return array[idx], idx\n",
    "\n",
    "        # find the nearest peak\n",
    "        peak_ids = scipy.signal.find_peaks(history[2])[0]\n",
    "\n",
    "        # if no peak appears, return nan\n",
    "        if len(peak_ids) == 0:\n",
    "            return float(\"nan\"), float(\"nan\"), float(\"nan\"), float(\"nan\")\n",
    "\n",
    "        prices = history[0, peak_ids]\n",
    "        optimal_price, idx = find_nearest(prices, original_price)\n",
    "        reward_95 =  history[2, peak_ids[idx]]*0.95\n",
    "        volume, volume_idx = find_volume(history[2], peak_ids[idx], reward_95) \n",
    "\n",
    "        min_price = history[0, volume_idx][0].item()\n",
    "        max_price = history[0, volume_idx][1].item()\n",
    "        mean_booking = history[1, peak_ids[idx]]\n",
    "        return optimal_price, mean_booking, min_price, max_price\n",
    "\n",
    "    def __visalize(self, history, optimal_price, original_price, min_price, max_price, qid, root):\n",
    "        fig, ax = plt.subplots()\n",
    "        ax.grid(True)\n",
    "\n",
    "        ax.plot(history[0], history[-1], color=\"blue\")\n",
    "\n",
    "        if not math.isnan(optimal_price):\n",
    "            ax.axvline(x=original_price, color=\"green\")\n",
    "            ax.axvline(x=optimal_price, color=\"red\")\n",
    "            ax.legend([\"reward curve\", \"original price\", \"optimal price\"])\n",
    "            ax.axvline(x=min_price, color=\"red\", ls=\"--\")\n",
    "            ax.axvline(x=max_price, color=\"red\", ls=\"--\")\n",
    "\n",
    "        else:\n",
    "            ax.axvline(x=original_price, color=\"green\")\n",
    "            ax.legend([\"original price\", \"reward curve\"])\n",
    "\n",
    "        fig.tight_layout()\n",
    "#         fig.savefig(root / f\"reward_plot_qid_{qid}.png\", dpi=300)\n",
    "\n",
    "    def __make_dataframe(self, qid, original_price, optimal_price, min_price, max_price, root,  booking_2022, booking_2023, pps, areas, own_areas, booking_2023_label):\n",
    "        \"\"\"\n",
    "        Creates a pandas DataFrame from inputs and saves as csv file.\n",
    "\n",
    "            Parameters:\n",
    "                qid (int): Ad qid\n",
    "                original_price (float): Ad original price\n",
    "                optimal_price (float): Ad optimal price\n",
    "                margin (float): Ad optimal price margin\n",
    "                root (str, Path): Root path for csv file.\n",
    "\n",
    "            Returns:\n",
    "                None\n",
    "        \"\"\"\n",
    "        columns = [\n",
    "            \"Qid\",\n",
    "            \"Original price\",\n",
    "            \"Optimal price\",\n",
    "            \"Min_optimal_preis_5%\",\n",
    "            \"Max_optimal_preis_5%_margin\",\n",
    "            \"PPSVACWert\",\n",
    "            \"Auslastung VJ\", \n",
    "            \"Auslastung 2023\",\n",
    "            \"Auslastung 2023 vorhergesagt\", \n",
    "            \"Anzahl der FlÃ¤chen im Umfeld\", \n",
    "            \"Anzahl der EigenflÃ¤chen im Umfeld\"\n",
    "        ]\n",
    "        data = np.array(\n",
    "            [\n",
    "                [\n",
    "                    qid,\n",
    "                    original_price,\n",
    "                    optimal_price,\n",
    "                    min_price, \n",
    "                    max_price,\n",
    "                    pps,\n",
    "                    booking_2022,\n",
    "                    booking_2023_label,\n",
    "                    booking_2023,                     \n",
    "                    areas,\n",
    "                    own_areas\n",
    "                ]\n",
    "            ]\n",
    "        )\n",
    "        df = pd.DataFrame(columns=columns, data=data)\n",
    "        df.Qid = df.Qid.astype(int)\n",
    "#         df.to_csv(root / f\"result_qid_{qid}.csv\", index=False)\n",
    "\n",
    "        return df\n",
    "\n",
    "    def __call__(self, qid: int):\n",
    "        \"\"\"\n",
    "        Return the optimal price and the 5 percent margin for given `qid`.\n",
    "\n",
    "            Parameters:\n",
    "                qid (int): Ad qid\n",
    "\n",
    "            Returns:\n",
    "                result (tuple(float, float)): Ad optimal price and margin.\n",
    "                If the optimum does not exist, returns (nan, nan)\n",
    "        \"\"\"\n",
    "        if not isinstance(qid, int):\n",
    "            raise TypeError(f\"Expected qid to be type of int, but got {type(qid)}.\")\n",
    "\n",
    "        if qid < 0:\n",
    "            raise ValueError(\n",
    "                f\"Expected qid to be greather or equal to zero, but got {qid}\"\n",
    "            )\n",
    "\n",
    "\n",
    "        *qid_data, booking_2022, PPS, area, own_area, booking_2023 = self.__get_qid_data(qid)\n",
    "\n",
    "        original_price, history, mean_booking = self.__grid_search(qid_data)\n",
    "        optimal_price, mean_b, min_price, max_price = self.__find_optimum(history, original_price, mean_booking)\n",
    "        df=self.__make_dataframe(qid, original_price, optimal_price, min_price, max_price, self.out_dir, booking_2022, mean_b, PPS, area[0], own_area[0], booking_2023)\n",
    "#         self.__visalize(history, optimal_price, original_price, min_price, max_price, qid, self.out_dir)\n",
    "        return df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5e086131",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = PriceOptimizer('./final_data/', './results/', 0, 100, 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b9ed25aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "data=pd.read_pickle('final_data/data.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cf2bf39f",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_qids = np.load(\"data/val_qids_1000.npy\")\n",
    "test_qids.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f82fe991",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_Einwohner = pd.read_pickle('data/df_gesamt_15_08_prepocessed_einworner_added.pkl')[[\"Qid\", \"Einwohner\", \"GJ\"]]\n",
    "data_Einwohner = data_Einwohner[data_Einwohner.GJ == 2023]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d4d60555",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe = optimizer(int(test_qids[0]))\n",
    "for qid in test_qids[1:]:\n",
    "    dataframe=pd.concat([dataframe, optimizer(int(qid))])    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f6bfafac",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_data = pd.merge(left=dataframe, right=data_Einwohner, on=\"Qid\", how=\"left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b0239380",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe.to_excel('./inference_1000_qids_volume.xlsx', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
