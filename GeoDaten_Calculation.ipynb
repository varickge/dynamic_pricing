{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "957b4e52",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import math\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "# from haversine import haversine, Unit #It can also be used to calculate the haversine distance, but a loop is needed to iterate over lat and lon."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca2f7d73",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set option for checking full data rows\n",
    "\n",
    "# pd.set_option('display.max_rows', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ddfaa86",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_pickle('./data/df_gesamt_15_08_prepocessed_einworner_added.pkl')\n",
    "data['GJ'] = data['GJ'].astype(float, errors='raise')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa6dbd03",
   "metadata": {},
   "source": [
    "# Truncated missing years"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af6fedb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_year_having_qid = data[data.GJ == 2023].Qid\n",
    "data = data[data.Qid.isin(target_year_having_qid)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc1c9098",
   "metadata": {},
   "outputs": [],
   "source": [
    "# splitting data to years\n",
    "data_2018 = data[data[\"GJ\"] == 2018]\n",
    "data_2019 = data[data[\"GJ\"] == 2019]\n",
    "data_2020 = data[data[\"GJ\"] == 2020]\n",
    "data_2021 = data[data[\"GJ\"] == 2021]\n",
    "data_2022 = data[data[\"GJ\"] == 2022]\n",
    "data_2023 = data[data[\"GJ\"] == 2023]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "999ce764",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # haversine distance calculator function \n",
    "\n",
    "def haversine_distance(lat1, lon1, lat2, lon2):\n",
    "    \"\"\"\n",
    "    Calculate the Haversine distance between two points on the Earth.\n",
    "\n",
    "    Parameters:\n",
    "    - lat1 (float): Latitude of the first point in degrees.\n",
    "    - lon1 (float): Longitude of the first point in degrees.\n",
    "    - lat2 (float): Latitude of the second point in degrees.\n",
    "    - lon2 (float): Longitude of the second point in degrees.\n",
    "\n",
    "    Returns:\n",
    "    - float: Distance between the two points in meters.\n",
    "\n",
    "    Note:\n",
    "    This function assumes the Earth is a perfect sphere with a radius of 6,371,000 meters.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Convert latitude and longitude from degrees to radians\n",
    "    lat1, lon1, lat2, lon2 = np.radians([lat1, lon1, lat2, lon2])\n",
    "\n",
    "    # Haversine formula \n",
    "    dlat = lat2 - lat1\n",
    "    dlon = lon2 - lon1\n",
    "    a = np.sin(dlat/2.0)**2 + np.cos(lat1) * np.cos(lat2) * np.sin(dlon/2.0)**2\n",
    "    c = 2 * np.arctan2(np.sqrt(a), np.sqrt(1-a))\n",
    "\n",
    "    # Radius of Earth in kilometers\n",
    "    r = 6371.0\n",
    "    return r * c\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da8c1aca",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_distances(data, max_dist=0.2):\n",
    "    # changing type of data for agg\n",
    "    data.PLZ = data.PLZ.astype('float64')\n",
    "\n",
    "    # taking unique \"Qid\"s and max of other (PLZ, AU, etc) columns\n",
    "#     data = data.groupby(\"Qid\").agg({'PLZ': 'max', 'Au': 'max', 'Laenge': 'max', 'Breite': 'max'}).reset_index()\n",
    "    data = data.groupby(\"Qid\").agg({'PLZ': 'max', 'Laenge': 'max', 'Breite': 'max'}).reset_index()\n",
    "    \n",
    "\n",
    "    # cutting `plz`, e.g. plz[0] is 34678, now plz[0] is 346 (Clustering regions with zip code). \n",
    "    data['join'] = data['PLZ'].astype(str).apply(lambda x: x[:3])\n",
    "\n",
    "    # copying data for distance calculation\n",
    "    data_copy1 = data.copy()\n",
    "    data_copy2 = data.copy()\n",
    "\n",
    "    # merging the same df for commonality\n",
    "    ergebnis = pd.merge(data_copy1, data_copy2, on='join', suffixes=['1', '2'])\n",
    "\n",
    "    # defining longitudes and latitudes\n",
    "    lat1 = np.array(ergebnis['Laenge1'].values)\n",
    "    lat2 = np.array(ergebnis['Laenge2'].values)\n",
    "    lon1 = np.array(ergebnis['Breite1'].values)\n",
    "    lon2 = np.array(ergebnis['Breite2'].values)\n",
    "    \n",
    "    # calculating distances and applying to the df\n",
    "    ergebnis['distance'] = haversine_distance(lat1, lon1, lat2, lon2)\n",
    "\n",
    "    # clustering data with max_dist param\n",
    "    ergebnis = ergebnis[(ergebnis['distance'] >= 0) & (ergebnis['distance'] <= max_dist)]\n",
    "\n",
    "    # dropping unnecessary columns\n",
    "#     ergebnis.drop(columns=[\"PLZ1\", \"Au1\", \"Laenge1\", \"Breite1\", \"join\", \"PLZ2\", \"Au2\", \"Laenge2\", \"Breite2\"], axis=1, inplace=True) \n",
    "    ergebnis.drop(columns=[\"PLZ1\", \"Laenge1\", \"Breite1\", \"join\", \"PLZ2\", \"Laenge2\", \"Breite2\"], axis=1, inplace=True) \n",
    "\n",
    "    return ergebnis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d72cd10",
   "metadata": {},
   "outputs": [],
   "source": [
    "distances_2018 = calc_distances(data_2018.copy())\n",
    "distances_2019 = calc_distances(data_2019.copy())\n",
    "distances_2020 = calc_distances(data_2020.copy())\n",
    "distances_2021 = calc_distances(data_2021.copy())\n",
    "distances_2022 = calc_distances(data_2022.copy())\n",
    "distances_2023 = calc_distances(data_2023.copy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3120b46c-146b-4118-b2b9-cdc69a969d84",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"2018: \", distances_2018.shape)\n",
    "print(\"2019: \", distances_2019.shape)\n",
    "print(\"2020: \", distances_2020.shape)\n",
    "print(\"2021: \", distances_2021.shape)\n",
    "print(\"2022: \", distances_2022.shape)\n",
    "print(\"2023: \", distances_2023.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5c2b8f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "distances_2018.to_csv(\"data/distances/distances_2018.csv\", index=False)\n",
    "distances_2019.to_csv(\"data/distances/distances_2019.csv\", index=False)\n",
    "distances_2020.to_csv(\"data/distances/distances_2020.csv\", index=False)\n",
    "distances_2021.to_csv(\"data/distances/distances_2021.csv\", index=False)\n",
    "distances_2022.to_csv(\"data/distances/distances_2022.csv\", index=False)\n",
    "distances_2023.to_csv(\"data/distances/distances_2023.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d9460cd",
   "metadata": {},
   "source": [
    "# GeoDaten_Calculation_03_08_2023"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "156f42a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_pickle(\"./data/df_gesamt_10_08_prepocessed.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ac863ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# splitting data to years\n",
    "data_2018 = data[data[\"GJ\"] == 2018].copy()\n",
    "data_2019 = data[data[\"GJ\"] == 2019].copy()\n",
    "data_2020 = data[data[\"GJ\"] == 2020].copy()\n",
    "data_2021 = data[data[\"GJ\"] == 2021].copy()\n",
    "data_2022 = data[data[\"GJ\"] == 2022].copy()\n",
    "data_2023 = data[data[\"GJ\"] == 2023].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6459a1e4",
   "metadata": {},
   "source": [
    "#### For each Qid1, ten nearest neighbors Qid2 are stored, distance and original data indexes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c1d7827",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_distances = []\n",
    "MAX_DISTANCE = 0.200\n",
    "\n",
    "for current_data, name in zip([data_2018, data_2019, data_2022, data_2023], [\"2018\", \"2019\", \"2022\", \"2023\"]):\n",
    "    \n",
    "    current_data[\"PLZ_short\"] = current_data[\"PLZ\"].apply(lambda x: x[:3])\n",
    "    current_data.reset_index(inplace=True)\n",
    "    current_data.set_index(\"PLZ_short\", inplace=True)\n",
    "    \n",
    "    distances_current = np.zeros((0, 4))\n",
    "    \n",
    "    for idx, (plz_index, row) in tqdm(enumerate(current_data.iterrows()), total=len(current_data)):\n",
    "        \n",
    "        potential_neighbours = current_data.loc[plz_index]\n",
    "        coordinates = potential_neighbours[['Breite', 'Laenge']].values\n",
    "        this_coordinates = current_data.iloc[idx][['Breite', 'Laenge']].values\n",
    "        \n",
    "        distances = haversine_distance(*this_coordinates , *coordinates.T)\n",
    "        sorted_indices = np.argsort(distances)[1:]\n",
    "        \n",
    "        if len(sorted_indices) == 0:\n",
    "            continue\n",
    "        elif len(sorted_indices) < 10:\n",
    "            sorted_distances = distances[sorted_indices]\n",
    "        else:            \n",
    "            sorted_distances = distances[sorted_indices[:10]]\n",
    "\n",
    "        kept_indices = np.where(sorted_distances <= MAX_DISTANCE)[0]\n",
    "        \n",
    "        if len(kept_indices) == 0:\n",
    "            continue\n",
    "        \n",
    "        top_N = potential_neighbours.iloc[kept_indices]\n",
    "        kept_distances = sorted_distances[kept_indices]\n",
    "        N = top_N.shape[0]\n",
    "        \n",
    "        tmp = np.stack([np.ones(N) * row[\"Qid\"], top_N[\"Qid\"].values, kept_distances, top_N[\"index\"]], axis=-1)\n",
    "        distances_current = np.concatenate([distances_current, tmp], axis=0)\n",
    "        \n",
    "    df = pd.DataFrame(columns=[\"Qid1\", \"Qid2\", \"distance\"], data=distances_current[:, :-1], index=distances_current[:, -1])\n",
    "    df.to_csv(f\"./data/distances_10_neighbours/distances_{name}.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "504fb29b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def haversine_distance(lat1, lon1, lat2, lon2):\n",
    "\n",
    "    lat1 = np.radians(lat1)\n",
    "    lon1 = np.radians(lon1)\n",
    "    lat2 = np.radians(lat2)\n",
    "    lon2 = np.radians(lon2)\n",
    "\n",
    "    # Do broadcasting\n",
    "    dlat = lat2 - lat1[..., None]\n",
    "    dlon = lon2 - lon1[..., None]\n",
    "    \n",
    "    a = np.sin(dlat/2.0)**2 + np.cos(lat1[..., None]) * np.cos(lat2) * np.sin(dlon/2.0)**2\n",
    "    c = 2 * np.arctan2(np.sqrt(a), np.sqrt(1-a))\n",
    "\n",
    "    r = 6371.0\n",
    "    return r * c"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
